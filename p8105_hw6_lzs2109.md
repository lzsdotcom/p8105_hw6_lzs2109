Data Science I Homework 6 - lzs2109
================
Louis Sharp
11/28/2021

``` r
library(tidyverse)
library(modelr)
```

### Problem 1

``` r
bweight_df = read_csv("./data/birthweight.csv")
```

    ## Rows: 4342 Columns: 20

    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## dbl (20): babysex, bhead, blength, bwt, delwt, fincome, frace, gaweeks, malf...

    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
bweight_df = 
  bweight_df %>% 
  mutate(
    babysex = as.factor(babysex),
    babysex = fct_recode(babysex, "male" = "1","female" = "2"),
    frace = as.factor(frace),
    frace = fct_recode(frace, "white" = "1", "black" = "2", "asian" = "3", 
                       "puerto rican" = "4", "other" = "8"),
    malform = as.factor(malform),
    malform = fct_recode(malform, "present" = "1", "absent" = "0"),
    mrace = as.factor(mrace),
    mrace = fct_recode(mrace, "white" = "1", "black" = "2", "asian" = "3", 
                       "puerto rican" = "4"))
```

``` r
map(bweight_df, ~sum(is.na(.))) %>% 
  as.data.frame()
```

    ##   babysex bhead blength bwt delwt fincome frace gaweeks malform menarche
    ## 1       0     0       0   0     0       0     0       0       0        0
    ##   mheight momage mrace parity pnumlbw pnumsga ppbmi ppwt smoken wtgain
    ## 1       0      0     0      0       0       0     0    0      0      0

There appear to be no missing values in the birth weight data set. A
possible regression model for birth weight may involve genetic factors
attributable to the parents as indirect predictors of weight instead of
direct predictors like the baby’s features (sex, length, head
circumference, etc). As such, we’ll propose a model that uses the
variables delwt (mother’s weight at delivery), mheight (the mother’s
height), ppwt (mother’s pre-pregnancy weight), and ppbmi (mother’s
pre-pregnancy BMI). If father’s weight, height, or BMI were available,
they would probably be interesting variables to include as well. This
proposed model is based solely on hypothesized underlying factors, and
we’ll use some data-driven info later to see how it could possibly be
improved.

``` r
proposed_model = 
  lm(bwt ~ delwt + mheight + ppbmi + ppwt, data = bweight_df)

bweight_df %>% 
  add_residuals(proposed_model) %>% 
  add_predictions(proposed_model) %>%
  ggplot(aes(x = pred, y = resid)) + 
    geom_point() + 
    labs(x = "Fitted Values", y = "Residuals")
```

![](p8105_hw6_lzs2109_files/figure-gfm/proposed%20model-1.png)<!-- -->

The fitted values versus residuals plot is already showing some
problematic trends in our proposed model, with the residuals not being
completely evenly distributed around 0. We can see that on the positive
side the residuals top out around just above +1500, but approach -2500
on the negative end. Although they are roughly evenly distributed, there
are a noticeable amount of points below -1500 for the residuals, with no
such points above +1500, save for one.

``` r
lm(bwt ~ blength + gaweeks, data = bweight_df) %>% 
  broom::tidy()
```

    ## # A tibble: 3 × 5
    ##   term        estimate std.error statistic  p.value
    ##   <chr>          <dbl>     <dbl>     <dbl>    <dbl>
    ## 1 (Intercept)  -4348.      98.0      -44.4 0       
    ## 2 blength        129.       1.99      64.6 0       
    ## 3 gaweeks         27.0      1.72      15.7 2.36e-54

``` r
lm(bwt ~ bhead + 
         blength + 
         babysex + 
         bhead * blength + 
         blength * babysex + 
         bhead * babysex + 
         bhead * blength * babysex, 
         data = bweight_df) %>% 
broom::tidy()
```

    ## # A tibble: 8 × 5
    ##   term                         estimate std.error statistic      p.value
    ##   <chr>                           <dbl>     <dbl>     <dbl>        <dbl>
    ## 1 (Intercept)                 -7177.     1265.       -5.67  0.0000000149
    ## 2 bhead                         182.       38.1       4.78  0.00000184  
    ## 3 blength                       102.       26.2       3.90  0.0000992   
    ## 4 babysexfemale                6375.     1678.        3.80  0.000147    
    ## 5 bhead:blength                  -0.554     0.780    -0.710 0.478       
    ## 6 blength:babysexfemale        -124.       35.1      -3.52  0.000429    
    ## 7 bhead:babysexfemale          -198.       51.1      -3.88  0.000105    
    ## 8 bhead:blength:babysexfemale     3.88      1.06      3.67  0.000245

The above given models are the ones that we will be comparing our
proposed model to.

``` r
cv_df = 
  crossv_mc(bweight_df, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df = 
  cv_df %>% 
  mutate(
    proposed_model  = map(train, ~lm(bwt ~ delwt + mheight + ppbmi + ppwt, data = .x)),
    model_1         = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    model_2         = map(train, ~lm(bwt ~ bhead + 
                                       blength + 
                                       babysex + 
                                       bhead * blength + 
                                       blength * babysex + 
                                       bhead * babysex + 
                                       bhead * blength * babysex,
                                     data = .x))) %>% 
  mutate(
    rmse_proposed_model = map2_dbl(proposed_model, test, ~rmse(model = .x, data = .y)),
    rmse_model_1        = map2_dbl(model_1, test, ~rmse(model = .x, data = .y)),
    rmse_model_2        = map2_dbl(model_2, test, ~rmse(model = .x, data = .y)))

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin()
```

![](p8105_hw6_lzs2109_files/figure-gfm/cross%20validation-1.png)<!-- -->

``` r
cv_df %>% head()
```

    ## # A tibble: 6 × 9
    ##   train test  .id   proposed_model model_1 model_2 rmse_proposed_m… rmse_model_1
    ##   <lis> <lis> <chr> <list>         <list>  <list>             <dbl>        <dbl>
    ## 1 <tib… <tib… 001   <lm>           <lm>    <lm>                498.         319.
    ## 2 <tib… <tib… 002   <lm>           <lm>    <lm>                495.         328.
    ## 3 <tib… <tib… 003   <lm>           <lm>    <lm>                487.         333.
    ## 4 <tib… <tib… 004   <lm>           <lm>    <lm>                500.         363.
    ## 5 <tib… <tib… 005   <lm>           <lm>    <lm>                460.         333.
    ## 6 <tib… <tib… 006   <lm>           <lm>    <lm>                480.         348.
    ## # … with 1 more variable: rmse_model_2 <dbl>

Clearly, from the plot of root mean squared errors from our proposed
model compared to the two given in the homework assignment, our proposed
model isn’t great. The RMSE is largely between 450 and 500, up to 525,
while this same error measure is reduced to between 300 and 375 for the
first model, and between 275 and 325 for the second model with the
interaction terms. This does make sense being that the model we proposed
used indirect measures that may or may not be related to actual
predictors of the baby’s weight, whereas the first model used the baby’s
actual length and gestational age, which are more direct predictors of
how much a baby weights. Obviously, the longer a baby is, the more they
will weigh. The second model also used direct features of the baby such
as their head circumference, weight, and sex, in addition to the
interactions between these variables. We can reasonably assume that the
larger a baby’s head is, the longer their body is, and the baby’s sex
would be more direct predictors of the baby’s weight. Our proposed
model’s higher error makes sense in retrospect, because if we fit a
model that includes all variables (below), we can see that of the ones
we chose in our hypothesized and non-data-driven model, only delwt has a
p-value below significance level of 0.05. Had we chosen another
mother-associated non-genetic factor such as smoken (number of
cigarettes smoked during pregnancy), we would have likely achieved a
better model.

``` r
lm(bwt ~ ., data = bweight_df) %>% summary()
```

    ## 
    ## Call:
    ## lm(formula = bwt ~ ., data = bweight_df)
    ## 
    ## Residuals:
    ##      Min       1Q   Median       3Q      Max 
    ## -1097.68  -184.86    -3.33   173.09  2344.15 
    ## 
    ## Coefficients: (3 not defined because of singularities)
    ##                     Estimate Std. Error t value Pr(>|t|)    
    ## (Intercept)       -6265.3914   660.4011  -9.487  < 2e-16 ***
    ## babysexfemale        28.7073     8.4652   3.391 0.000702 ***
    ## bhead               130.7781     3.4523  37.881  < 2e-16 ***
    ## blength              74.9536     2.0217  37.075  < 2e-16 ***
    ## delwt                 4.1007     0.3948  10.386  < 2e-16 ***
    ## fincome               0.2898     0.1795   1.614 0.106551    
    ## fraceblack           14.3313    46.1501   0.311 0.756168    
    ## fraceasian           21.2361    69.2960   0.306 0.759273    
    ## fracepuerto rican   -46.9962    44.6782  -1.052 0.292912    
    ## fraceother            4.2969    74.0741   0.058 0.953745    
    ## gaweeks              11.5494     1.4654   7.882 4.06e-15 ***
    ## malformpresent        9.7650    70.6259   0.138 0.890039    
    ## menarche             -3.5508     2.8951  -1.226 0.220083    
    ## mheight               9.7874    10.3116   0.949 0.342588    
    ## momage                0.7593     1.2221   0.621 0.534418    
    ## mraceblack         -151.4354    46.0453  -3.289 0.001014 ** 
    ## mraceasian          -91.3866    71.9190  -1.271 0.203908    
    ## mracepuerto rican   -56.4787    45.1369  -1.251 0.210901    
    ## parity               95.5411    40.4793   2.360 0.018307 *  
    ## pnumlbw                   NA         NA      NA       NA    
    ## pnumsga                   NA         NA      NA       NA    
    ## ppbmi                 4.3538    14.8913   0.292 0.770017    
    ## ppwt                 -3.4716     2.6121  -1.329 0.183913    
    ## smoken               -4.8544     0.5871  -8.269  < 2e-16 ***
    ## wtgain                    NA         NA      NA       NA    
    ## ---
    ## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
    ## 
    ## Residual standard error: 272.5 on 4320 degrees of freedom
    ## Multiple R-squared:  0.7183, Adjusted R-squared:  0.717 
    ## F-statistic: 524.6 on 21 and 4320 DF,  p-value: < 2.2e-16

### Problem 2

``` r
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

    ## Registered S3 method overwritten by 'hoardr':
    ##   method           from
    ##   print.cache_info httr

    ## using cached file: ~/Library/Caches/R/noaa_ghcnd/USW00094728.dly

    ## date created (size, mb): 2021-11-28 11:33:19 (7.614)

    ## file min/max dates: 1869-01-01 / 2021-11-30

Loaded the data in above, and below we will do 5000 bootstrap samples
and estimates for *r̂*<sup>2</sup> and
log(*β̂*<sub>0</sub> \* *β̂*<sub>1</sub>). Then, we’ll plot the
distribution of the estimates and describe them.

``` r
weather_bootstraps = 
  weather_df %>% 
  bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results_brglance = map(models, broom::glance),
    results_brtidy = map(models, broom::tidy)) %>% 
  select(.id, results_brglance, results_brtidy)

weather_bootstraps %>% 
  unnest(results_brglance) %>% 
  ggplot(aes(x = r.squared)) +
  geom_histogram()
```

    ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.

![](p8105_hw6_lzs2109_files/figure-gfm/bootstraps%20and%20plots-1.png)<!-- -->

The distribution of our 5000 bootstrap estimates for *r̂*<sup>2</sup>
appears to follow a fairly normal distribution, with a bit of a tail on
the lower end of the *r̂*<sup>2</sup> values. The distribution appears to
be centered around an *r̂*<sup>2</sup> value of 0.915.

``` r
weather_bootstraps %>% 
  unnest(results_brtidy) %>% 
  select(.id, term, estimate) %>% 
  pivot_wider(names_from = term, values_from = estimate) %>% 
  janitor::clean_names() %>% 
  mutate(log = log10(intercept * tmin)) %>% 
  ggplot(aes(x = log)) +
  geom_histogram()
```

    ## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.

![](p8105_hw6_lzs2109_files/figure-gfm/plots%202-1.png)<!-- -->

The distribution of our 5000 bootstrap estimates for
log(*β̂*<sub>0</sub> \* *β̂*<sub>1</sub>) also appears to follow a fairly
normal distribution, similar to the *r̂*<sup>2</sup> values. The
log(*β̂*<sub>0</sub> \* *β̂*<sub>1</sub>) distribution looks to be
centered around a value of 0.875.

``` r
rsquared_ci = 
  weather_bootstraps %>% 
  unnest(results_brglance) %>% 
  summarize(ci_lower = quantile(r.squared, 0.025), 
            ci_upper = quantile(r.squared, 0.975))
rsquared_ci
```

    ## # A tibble: 1 × 2
    ##   ci_lower ci_upper
    ##      <dbl>    <dbl>
    ## 1    0.894    0.927

``` r
logbeta_ci = 
  weather_bootstraps %>% 
  unnest(results_brtidy) %>% 
  select(.id, term, estimate) %>% 
  pivot_wider(names_from = term, values_from = estimate) %>% 
  janitor::clean_names() %>% 
  mutate(log = log10(intercept * tmin)) %>% 
  summarize(ci_lower = quantile(log, 0.025), 
            ci_upper = quantile(log, 0.975))
logbeta_ci
```

    ## # A tibble: 1 × 2
    ##   ci_lower ci_upper
    ##      <dbl>    <dbl>
    ## 1    0.853    0.895

Above, we produced 95% confidence intervals for our bootstrapped
estimates of *r̂*<sup>2</sup> and
log(*β̂*<sub>0</sub> \* *β̂*<sub>1</sub>). The 95% confidence interval for
*r̂*<sup>2</sup> is 0.894, 0.927 and for
log(*β̂*<sub>0</sub> \* *β̂*<sub>1</sub>), the 95% confidence interval is
0.853, 0.895. We can say with 95% confidence that the true population
parameter lies between these upper and lower bounds for both of these
measures.
