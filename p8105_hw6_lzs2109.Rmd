---
title: "Data Science I Homework 6 - lzs2109"
author: "Louis Sharp"
date: "11/28/2021"
output: github_document
---

```{r, message = F}
library(tidyverse)
library(modelr)
```


### Problem 1

```{r, data import and tidy}
bweight_df = read_csv("./data/birthweight.csv")

bweight_df = 
  bweight_df %>% 
  mutate(
    babysex = as.factor(babysex),
    babysex = fct_recode(babysex, "male" = "1","female" = "2"),
    frace = as.factor(frace),
    frace = fct_recode(frace, "white" = "1", "black" = "2", "asian" = "3", 
                       "puerto rican" = "4", "other" = "8"),
    malform = as.factor(malform),
    malform = fct_recode(malform, "present" = "1", "absent" = "0"),
    mrace = as.factor(mrace),
    mrace = fct_recode(mrace, "white" = "1", "black" = "2", "asian" = "3", 
                       "puerto rican" = "4"))
```

```{r, na values}
map(bweight_df, ~sum(is.na(.))) %>% 
  as.data.frame()
```

There appear to be no missing values in the birth weight data set. A possible regression model for birth weight may involve genetic factors attributable to the parents as indirect predictors of weight instead of direct predictors like the baby's features (sex, length, head circumference, etc). As such, we'll propose a model that uses the variables delwt (mother's weight at delivery), mheight (the mother's height), ppwt (mother's pre-pregnancy weight), and ppbmi (mother's pre-pregnancy BMI). If father's weight, height, or BMI were available, they would probably be interesting variables to include as well. This proposed model is based solely on hypothesized underlying factors, and we'll use some data-driven info later to see how it could possibly be improved.

```{r, proposed model}
proposed_model = 
  lm(bwt ~ delwt + mheight + ppbmi + ppwt, data = bweight_df)

bweight_df %>% 
  add_residuals(proposed_model) %>% 
  add_predictions(proposed_model) %>%
  ggplot(aes(x = pred, y = resid)) + 
    geom_point() + 
    labs(x = "Fitted Values", y = "Residuals")
```

The fitted values versus residuals plot is already showing some problematic trends in our proposed model, with the residuals not being completely evenly distributed around 0. We can see that on the positive side the residuals top out around just above +1500, but approach -2500 on the negative end. Although they are roughly evenly distributed, there are a noticeable amount of points below -1500 for the residuals, with no such points above +1500, save for one.

```{r, given models}
lm(bwt ~ blength + gaweeks, data = bweight_df) %>% 
  broom::tidy()


lm(bwt ~ bhead + 
         blength + 
         babysex + 
         bhead * blength + 
         blength * babysex + 
         bhead * babysex + 
         bhead * blength * babysex, 
         data = bweight_df) %>% 
broom::tidy()
```

The above given models are the ones that we will be comparing our proposed model to.

```{r, cross validation}
cv_df = 
  crossv_mc(bweight_df, 100) %>% 
  mutate(
    train = map(train, as_tibble),
    test = map(test, as_tibble))

cv_df = 
  cv_df %>% 
  mutate(
    proposed_model  = map(train, ~lm(bwt ~ delwt + mheight + ppbmi + ppwt, data = .x)),
    model_1         = map(train, ~lm(bwt ~ blength + gaweeks, data = .x)),
    model_2         = map(train, ~lm(bwt ~ bhead + 
                                       blength + 
                                       babysex + 
                                       bhead * blength + 
                                       blength * babysex + 
                                       bhead * babysex + 
                                       bhead * blength * babysex,
                                     data = .x))) %>% 
  mutate(
    rmse_proposed_model = map2_dbl(proposed_model, test, ~rmse(model = .x, data = .y)),
    rmse_model_1        = map2_dbl(model_1, test, ~rmse(model = .x, data = .y)),
    rmse_model_2        = map2_dbl(model_2, test, ~rmse(model = .x, data = .y)))

cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model", 
    values_to = "rmse",
    names_prefix = "rmse_") %>% 
  mutate(model = fct_inorder(model)) %>% 
  ggplot(aes(x = model, y = rmse)) + 
  geom_violin()

cv_df %>% head()
```

Clearly, from the plot of root mean squared errors from our proposed model compared to the two given in the homework assignment, our proposed model isn't great. The RMSE is largely between 450 and 500, up to 525, while this same error measure is reduced to between 300 and 375 for the first model, and between 275 and 325 for the second model with the interaction terms. This does make sense being that the model we proposed used indirect measures that may or may not be related to actual predictors of the baby's weight, whereas the first model used the baby's actual length and gestational age, which are more direct predictors of how much a baby weights. Obviously, the longer a baby is, the more they will weigh. The second model also used direct features of the baby such as their head circumference, weight, and sex, in addition to the interactions between these variables. We can reasonably assume that the larger a baby's head is, the longer their body is, and the baby's sex would be more direct predictors of the baby's weight. Our proposed model's higher error makes sense in retrospect, because if we fit a model that includes all variables (below), we can see that of the ones we chose in our hypothesized and non-data-driven model, only delwt has a p-value below significance level of 0.05. Had we chosen another mother-associated non-genetic factor such as smoken (number of cigarettes smoked during pregnancy), we would have likely achieved a better model.

```{r, all vars model}
lm(bwt ~ ., data = bweight_df) %>% summary()
```


### Problem 2

```{r, data import 2}
weather_df = 
  rnoaa::meteo_pull_monitors(
    c("USW00094728"),
    var = c("PRCP", "TMIN", "TMAX"), 
    date_min = "2017-01-01",
    date_max = "2017-12-31") %>%
  mutate(
    name = recode(id, USW00094728 = "CentralPark_NY"),
    tmin = tmin / 10,
    tmax = tmax / 10) %>%
  select(name, id, everything())
```

Loaded the data in above, and below we will do 5000 bootstrap samples and estimates for $\hat{r}^2$ and log($\hat{\beta}_0 * \hat{\beta}_1$). Then, we'll plot the distribution of the estimates and describe them.

```{r, bootstraps and plots}
weather_bootstraps = 
  weather_df %>% 
  bootstrap(n = 5000) %>% 
  mutate(
    models = map(strap, ~lm(tmax ~ tmin, data = .x)),
    results_brglance = map(models, broom::glance),
    results_brtidy = map(models, broom::tidy)) %>% 
  select(.id, results_brglance, results_brtidy)

weather_bootstraps %>% 
  unnest(results_brglance) %>% 
  ggplot(aes(x = r.squared)) +
  geom_histogram()
```

The distribution of our 5000 bootstrap estimates for $\hat{r}^2$ appears to follow a fairly normal distribution, with a bit of a tail on the lower end of the $\hat{r}^2$ values. The distribution appears to be centered around an $\hat{r}^2$ value of 0.915.

```{r, plots 2}
weather_bootstraps %>% 
  unnest(results_brtidy) %>% 
  select(.id, term, estimate) %>% 
  pivot_wider(names_from = term, values_from = estimate) %>% 
  janitor::clean_names() %>% 
  mutate(log = log10(intercept * tmin)) %>% 
  ggplot(aes(x = log)) +
  geom_histogram()
```

The distribution of our 5000 bootstrap estimates for log($\hat{\beta}_0 * \hat{\beta}_1$) also appears to follow a fairly normal distribution, similar to the $\hat{r}^2$ values. The log($\hat{\beta}_0 * \hat{\beta}_1$) distribution looks to be centered around a value of 0.875.

```{r, confidence intervals}
rsquared_ci = 
  weather_bootstraps %>% 
  unnest(results_brglance) %>% 
  summarize(ci_lower = quantile(r.squared, 0.025), 
            ci_upper = quantile(r.squared, 0.975))
rsquared_ci

logbeta_ci = 
  weather_bootstraps %>% 
  unnest(results_brtidy) %>% 
  select(.id, term, estimate) %>% 
  pivot_wider(names_from = term, values_from = estimate) %>% 
  janitor::clean_names() %>% 
  mutate(log = log10(intercept * tmin)) %>% 
  summarize(ci_lower = quantile(log, 0.025), 
            ci_upper = quantile(log, 0.975))
logbeta_ci
```

Above, we produced 95% confidence intervals for our bootstrapped estimates of $\hat{r}^2$ and log($\hat{\beta}_0 * \hat{\beta}_1$). The 95% confidence interval for $\hat{r}^2$ is `r round(rsquared_ci, 3)` and for log($\hat{\beta}_0 * \hat{\beta}_1$), the 95% confidence interval is `r round(logbeta_ci, 3)`. We can say with 95% confidence that the true population parameter lies between these upper and lower bounds for both of these measures.
